{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'Manga_Fiction'\n",
    "URL = 'https://www.amazon.com/Best-Sellers-Books-Science-Fiction-Manga/zgbs/books/13436201/ref=zg_bs_nav_books_3_4367'\n",
    "\n",
    "out_dir = '../out'\n",
    "out_filepath = f'{out_dir}/{name}_Amazon_Info_Top50.xlsx'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using selenium to run javascript based web pages (we need to scroll down to get full length)\n",
    "browser=webdriver.Chrome()\n",
    "browser.get(URL)\n",
    "\n",
    "# waiting for amazon to run the api to get new data\n",
    "time.sleep(5)\n",
    "\n",
    "# initializing values\n",
    "curr_height = 0\n",
    "total_height = browser.execute_script(f'return document.body.scrollHeight')\n",
    "\n",
    "# continuous scrolling because amazon used lazy loading\n",
    "while curr_height < total_height:\n",
    "    # scroll by pixel counts\n",
    "    browser.execute_script(f'window.scrollTo(0,{curr_height})')\n",
    "    \n",
    "    # each time scroll 100 pixels\n",
    "    curr_height += 100\n",
    "\n",
    "    # waiting before each scroll\n",
    "    time.sleep(0.1)\n",
    "\n",
    "    # update the total_height when data new comes into picture    \n",
    "    total_height = browser.execute_script(f'return document.body.scrollHeight')\n",
    "\n",
    "# waiting for amazon to run the api to get new data\n",
    "time.sleep(2)\n",
    "\n",
    "# Parsing website's html content\n",
    "soup = BeautifulSoup(browser.page_source, \"html.parser\")\n",
    "\n",
    "browser.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_audio_book(book_div):\n",
    "    try:\n",
    "        book_type_span = book_div.find('span',class_='a-size-small a-color-secondary a-text-normal')\n",
    "        book_type = book_type_span.get_text(strip=True)\n",
    "\n",
    "        return book_type == 'Audible Audiobook'\n",
    "    \n",
    "    except Exception as e:\n",
    "        raise Exception(e)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking for book Content\n",
    "book_list_div = soup.find('div', class_ = 'p13n-gridRow _cDEzb_grid-row_3Cywl')\n",
    "book_divs = book_list_div.find_all('div', id=\"gridItemRoot\")\n",
    "\n",
    "info = {\n",
    "    'amazon_links': [],\n",
    "    'title': [],\n",
    "    'author': [],\n",
    "    'review': [],\n",
    "    'rating': [],\n",
    "    'price': [],\n",
    "    'length': [],\n",
    "    'rank': [],\n",
    "    'size': []\n",
    "}\n",
    "\n",
    "for book_div in book_divs:\n",
    "\n",
    "    # check if book type\n",
    "    if is_audio_book(book_div): continue\n",
    "\n",
    "    ############################ EXTRACTING ############################\n",
    "    # book link\n",
    "    book_link_a = book_div.find('a',class_='a-link-normal')\n",
    "    book_link = f'https://www.amazon.com/{book_link_a[\"href\"]}'\n",
    "    \n",
    "    # book title\n",
    "    book_title_a = book_div.find('div',class_='_cDEzb_p13n-sc-css-line-clamp-1_1Fn1y')\n",
    "    book_title = book_title_a.get_text(strip=True)\n",
    "   \n",
    "\n",
    "    # book author\n",
    "    book_author_div = book_div.find('div',class_='a-row a-size-small')\n",
    "    if book_author_div == None:\n",
    "        continue\n",
    "\n",
    "    book_author = book_author_div.get_text(strip=True)\n",
    "    \n",
    "\n",
    "    # book review\n",
    "    book_review_span = book_div.find('div',class_='a-icon-row')\n",
    "    if book_review_span == None:\n",
    "        print(book_title)\n",
    "        continue\n",
    "\n",
    "    book_review_div = book_review_span.find('span',class_='a-size-small')\n",
    "    book_review = book_review_div.get_text(strip=True)\n",
    "    \n",
    "\n",
    "\n",
    "    # book ratings\n",
    "    book_ratings_span = book_div.find('span',class_='a-icon-alt')\n",
    "    if book_ratings_span == None:\n",
    "        print(book_title)\n",
    "        continue\n",
    "\n",
    "    book_ratings = book_ratings_span.get_text(strip=True)\n",
    "\n",
    "    # book price\n",
    "    book_price_div = book_div.find('div',class_='_cDEzb_p13n-sc-price-animation-wrapper_3PzN2')\n",
    "    if book_price_div == None:\n",
    "        print(book_title)\n",
    "        continue\n",
    "    book_price_span = book_price_div.find('span',class_='_cDEzb_p13n-sc-price_3mJ9Z')\n",
    "    if book_price_span == None:\n",
    "        print(book_title)\n",
    "        continue\n",
    "\n",
    "    book_price = book_price_span.get_text(strip=True)\n",
    "\n",
    "    ############################ SAVING ############################\n",
    "    info['amazon_links'].append(book_link)\n",
    "    info['title'].append(book_title)\n",
    "    info['author'].append(book_author)\n",
    "    info['review'].append(book_review)\n",
    "    info['rating'].append(book_ratings)\n",
    "    info['price'].append(book_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [04:09<00:00,  5.19s/it]\n"
     ]
    }
   ],
   "source": [
    "# selecting amazon links column from excel\n",
    "books_urls = list(info['amazon_links'])\n",
    "\n",
    "browser=webdriver.Chrome()\n",
    "info['length']=[]\n",
    "\n",
    "for book_url in tqdm(books_urls):\n",
    "\n",
    "    # adding page length column to dataset\n",
    "    try:\n",
    "        browser.get(book_url)\n",
    "        html = browser.page_source\n",
    "        soup = BeautifulSoup(html, 'html.parser') \n",
    "        wrapper_div = soup.find('div', {'id':'rich_product_information'})\n",
    "        book_length_a = wrapper_div.find('a', class_ = 'a-popover-trigger a-declarative')\n",
    "        text = book_length_a.get_text()\n",
    "        second_index = text.find('pages')\n",
    "        book_length = text[:second_index]\n",
    "        info['length'].append(book_length)\n",
    "\n",
    "        \n",
    "    except Exception as e:\n",
    "        info['length'].append('NOT FOUND')\n",
    "\n",
    "browser.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [04:09<00:00,  5.19s/it]\n"
     ]
    }
   ],
   "source": [
    "# selecting amazon links column from excel\n",
    "books_urls = list(info['amazon_links'])\n",
    "\n",
    "browser=webdriver.Chrome()\n",
    "info['rank']=[]\n",
    "\n",
    "for book_url in tqdm(books_urls):\n",
    "\n",
    "    try:\n",
    "        browser.get(book_url)\n",
    "        html = browser.page_source\n",
    "        soup = BeautifulSoup(html, 'html.parser') \n",
    "        wrapper_div = soup.find_all('ul', class_ = 'a-unordered-list a-nostyle a-vertical a-spacing-none detail-bullet-list')[1]\n",
    "        best_seller_rank_span = wrapper_div.find('span', class_='a-text-bold')\n",
    "        text = wrapper_div.get_text()\n",
    "        start_index = text.find('#')\n",
    "        end_index = text.find('in')\n",
    "        rank = text[start_index: end_index]\n",
    "\n",
    "        info['rank'].append(rank)\n",
    "\n",
    "    except Exception as e:\n",
    "        info['rank'].append('NOT FOUND')\n",
    "    \n",
    "browser.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe\n",
    "df = pd.DataFrame(info)\n",
    "\n",
    "df.to_excel(out_filepath, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Reading the entire Excel file\n",
    "data = pd.read_excel('/Users/achaudhari/Desktop/Book Prediction New/out/Training.xlsx')\n",
    "\n",
    "# Define thresholds\n",
    "Threshold_small = 500 \n",
    "Threshold_large = 1000\n",
    "\n",
    "# Function to categorize book length\n",
    "def get_length_category(length):\n",
    "    if length <= Threshold_small:\n",
    "        return 'small'\n",
    "    elif length >= Threshold_large:\n",
    "        return 'large'\n",
    "    else:\n",
    "        return 'medium'\n",
    "\n",
    "# Assuming 'Length' is the column name that contains the book lengths\n",
    "# Apply the function to the 'Length' column\n",
    "data['Length_Category'] = data['Length'].apply(get_length_category)\n",
    "\n",
    "# Saving the updated DataFrame to a new Excel file\n",
    "data.to_excel('/Users/achaudhari/Desktop/Book Prediction New/length_size.xlsx', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
